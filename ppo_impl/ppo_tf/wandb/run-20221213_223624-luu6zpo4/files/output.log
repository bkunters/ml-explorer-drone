
Collecting batch trajectories...
Mean cumulative reward: 18.0
Updating the neural networks...
Epoch: 4, Policy loss: -0.012592417187988758
Epoch: 4, Value loss: 0.9241268038749695
Total time steps: 198
Collecting batch trajectories...
WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Flatten object at 0x102c22af0>, because it is not built.
WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.
WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Flatten object at 0x145cab1f0>, because it is not built.
WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Flatten object at 0x145cab1f0>, because it is not built.
WARNING:absl:Found untraced functions such as dense_4_layer_call_fn, dense_4_layer_call_and_return_conditional_losses, dense_5_layer_call_fn, dense_5_layer_call_and_return_conditional_losses, dense_6_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.
Mean cumulative reward: 13.142857142857142
Updating the neural networks...
Epoch: 4, Policy loss: -0.004368809051811695
Epoch: 4, Value loss: 1.0209927558898926
Total time steps: 474
Collecting batch trajectories...
Mean cumulative reward: 8.483870967741936
Updating the neural networks...
Epoch: 4, Policy loss: -0.013497298583388329
Epoch: 4, Value loss: 0.9795739054679871
Total time steps: 737
Collecting batch trajectories...
Mean cumulative reward: 7.853658536585366
Updating the neural networks...
Epoch: 4, Policy loss: -0.005938019137829542
Epoch: 4, Value loss: 0.9743643999099731
Total time steps: 1059
Collecting batch trajectories...
Mean cumulative reward: 8.294117647058824
Updating the neural networks...
Epoch: 4, Policy loss: -0.00024530396331101656
Epoch: 4, Value loss: 0.9899584650993347
Total time steps: 1482
Collecting batch trajectories...
Mean cumulative reward: 7.081967213114754
Updating the neural networks...
Epoch: 4, Policy loss: -0.005002027843147516
Epoch: 4, Value loss: 0.9782768487930298
Total time steps: 1914
Collecting batch trajectories...
Mean cumulative reward: 7.183098591549296
Updating the neural networks...
Epoch: 4, Policy loss: -0.0022290311753749847
Epoch: 4, Value loss: 0.9881149530410767
Total time steps: 2424
Collecting batch trajectories...
Mean cumulative reward: 7.493827160493828
Updating the neural networks...
Epoch: 4, Policy loss: -0.010928858071565628
Epoch: 4, Value loss: 0.9497866630554199
Total time steps: 3031
Collecting batch trajectories...
Mean cumulative reward: 6.406593406593407
Updating the neural networks...
Epoch: 4, Policy loss: -0.002208431251347065
Epoch: 4, Value loss: 0.9961928129196167
Total time steps: 3614
Collecting batch trajectories...
Mean cumulative reward: 5.227722772277228
Updating the neural networks...
Epoch: 4, Policy loss: -0.009886221960186958
Epoch: 4, Value loss: 0.971025288105011
Total time steps: 4142
Collecting batch trajectories...
Mean cumulative reward: 5.54954954954955
Updating the neural networks...
Epoch: 4, Policy loss: -0.001350482227280736
Epoch: 4, Value loss: 0.9754737615585327
Total time steps: 4758
Collecting batch trajectories...
Mean cumulative reward: 7.132231404958677
Updating the neural networks...
Epoch: 4, Policy loss: -0.006017942447215319
Epoch: 4, Value loss: 1.0432153940200806
Total time steps: 5621
Collecting batch trajectories...
Traceback (most recent call last):
  File "/Volumes/Work Disk Janina Mattes/DEV/University/ASP/ml-explorer-drone/ppo_impl/ppo_tf/ppo_tf.py", line 192, in <module>
    observation, reward, terminated, truncated, info = env.step(current_action)
  File "/Users/janinaalicamattes/miniforge3/envs/tensorflow_m1_ppo/lib/python3.9/site-packages/gym/wrappers/time_limit.py", line 50, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
  File "/Users/janinaalicamattes/miniforge3/envs/tensorflow_m1_ppo/lib/python3.9/site-packages/gym/wrappers/order_enforcing.py", line 37, in step
    return self.env.step(action)
  File "/Users/janinaalicamattes/miniforge3/envs/tensorflow_m1_ppo/lib/python3.9/site-packages/gym/wrappers/env_checker.py", line 39, in step
    return self.env.step(action)
  File "/Users/janinaalicamattes/miniforge3/envs/tensorflow_m1_ppo/lib/python3.9/site-packages/gym/envs/classic_control/cartpole.py", line 187, in step
    self.render()
  File "/Users/janinaalicamattes/miniforge3/envs/tensorflow_m1_ppo/lib/python3.9/site-packages/gym/envs/classic_control/cartpole.py", line 298, in render
    self.clock.tick(self.metadata["render_fps"])
KeyboardInterrupt